# -*- coding: utf-8 -*-
"""RAG Model for QA Bot(YardStick Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tU3JG19M4Zi1ocW2R3GFaal8xPMKwXMb
"""

#Installing and importing all the required Libraries
!pip install --upgrade openai
!pip install pinecone-client
!pip install unstructured
!pip install tiktoken
!pip install pypdf
!pip install langchain
!pip install -U langchain-community




import openai
import langchain
import pinecone
from langchain.document_loaders import PyPDFDirectoryLoader
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
from langchain.llms import OpenAI
import requests
import tempfile
import os

#Getting The PDF from the provided Link
def read_doc(pdf_url):
    try:
        response = requests.get(pdf_url)
        response.raise_for_status()

        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(response.content)
            tmp_file_path = tmp_file.name
        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()

        return documents

    except requests.exceptions.RequestException as e:
        print(f"Error downloading the PDF: {e}")
    except Exception as e:
        print(f"Error processing the PDF: {e}")

#Divide the PDF into chunks
def chunk_data(docs, chunk_size = 800, chunk_overlap = 50):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size = chunk_size, chunk_overlap = chunk_overlap)
    doc = text_splitter.split_documents(docs)
    return doc

doc = read_doc('https://www.indiabudget.gov.in/doc/budget_speech.pdf')#Url of the PDF or Document We want our module to learn From
len(doc)

#Embedding Technique of OPENAI
os.environ['OPENAI_API_KEY'] = 'sk-proj-7JM7dbkrCqKOWux9s1S2T3BlbkFJQKo8xZXsvRLSbfVGNiCF'
embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])

vectors = embeddings.embed_query("how are you?")
len(vectors)

#Vector Search DB in PineCone
os.environ['PINECONE_API_KEY'] = 'fdea4408-8b2b-4f96-9f7f-83c9e355a2aa'
from pinecone import Pinecone
Pinecone(pi_key=os.environ.get("PINECONE_API_KEY"))

from langchain.vectorstores import Pinecone
index = Pinecone.from_documents(doc, embeddings, index_name = "business-qa-bot")

#Cosine Similarity Retreive Results from VectorDB
def retrieve_query(query, k = 2):
    matching_results = index.similarity_search(query, k = k)
    return matching_results

from langchain.chains.question_answering import load_qa_chain
from langchain import OpenAI

llm = OpenAI(model_name = "text-embedding-ada-002", temperature = 0.5)
chain = load_qa_chain(llm, chain_type = "stuff")

#Searching from VectorDB
def retrieve_answers(query):
    doc_search = retrieve_query(query)
    print(doc_search)
    response = chain.run(input_documents = doc_search, question = query)
    return response

our_query = "How much the agriculture target will be increased by how many crore?"
answer  = retrieve_answers(our_query)
print(answer)

